{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9fbc62",
   "metadata": {
    "papermill": {
     "duration": 0.004995,
     "end_time": "2025-03-19T11:52:34.664297",
     "exception": false,
     "start_time": "2025-03-19T11:52:34.659302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Check version of Python and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646235f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:52:34.673861Z",
     "iopub.status.busy": "2025-03-19T11:52:34.673557Z",
     "iopub.status.idle": "2025-03-19T11:52:34.679337Z",
     "shell.execute_reply": "2025-03-19T11:52:34.678695Z"
    },
    "papermill": {
     "duration": 0.011718,
     "end_time": "2025-03-19T11:52:34.680476",
     "exception": false,
     "start_time": "2025-03-19T11:52:34.668758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e6cc50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:52:34.689826Z",
     "iopub.status.busy": "2025-03-19T11:52:34.689637Z",
     "iopub.status.idle": "2025-03-19T11:52:38.202386Z",
     "shell.execute_reply": "2025-03-19T11:52:38.201362Z"
    },
    "papermill": {
     "duration": 3.518967,
     "end_time": "2025-03-19T11:52:38.203860",
     "exception": false,
     "start_time": "2025-03-19T11:52:34.684893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should print True\n",
    "print(torch.cuda.device_count())  # Should print the number of available GPUs\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa20de",
   "metadata": {
    "papermill": {
     "duration": 0.004178,
     "end_time": "2025-03-19T11:52:38.212852",
     "exception": false,
     "start_time": "2025-03-19T11:52:38.208674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Remember to install all CUDA Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9e7372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:52:38.222663Z",
     "iopub.status.busy": "2025-03-19T11:52:38.222293Z",
     "iopub.status.idle": "2025-03-19T11:52:38.465307Z",
     "shell.execute_reply": "2025-03-19T11:52:38.464265Z"
    },
    "papermill": {
     "duration": 0.249488,
     "end_time": "2025-03-19T11:52:38.466691",
     "exception": false,
     "start_time": "2025-03-19T11:52:38.217203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-0849efcd2153>:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Packages:\n",
      "asteroid-filterbanks==0.4.0\n",
      "decord==0.6.0\n",
      "deepspeed==0.14.3\n",
      "docopt==0.6.2\n",
      "hjson==3.1.0\n",
      "HyperPyYAML==1.2.2\n",
      "importlib_metadata==7.1.0\n",
      "Jinja2==3.1.3\n",
      "julius==0.2.7\n",
      "lazy_loader==0.3\n",
      "lightning==2.1.3\n",
      "Mako==1.3.0\n",
      "Markdown==3.6\n",
      "MarkupSafe==2.1.4\n",
      "nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "nvidia-nvtx-cu12==12.1.105\n",
      "openai-whisper==20231117\n",
      "primePy==1.3\n",
      "pyannote.core==5.0.0\n",
      "pyannote.database==5.0.1\n",
      "pyannote.metrics==3.2.1\n",
      "pyannote.pipeline==3.0.1\n",
      "pydantic_core==2.14.6\n",
      "Pygments==2.17.2\n",
      "pytorch-metric-learning==2.4.1\n",
      "pytube==15.0.0\n",
      "PyYAML==6.0.1\n",
      "ruamel.yaml==0.18.5\n",
      "ruamel.yaml.clib==0.2.8\n",
      "speechbrain==0.5.16\n",
      "SQLAlchemy==2.0.25\n",
      "tensorboardX==2.6.2.2\n",
      "torch-audiomentations==0.11.0\n",
      "torch-pitch-shift==1.2.4\n",
      "triton==2.1.0\n",
      "typing_extensions==4.9.0\n",
      "Werkzeug==3.0.3\n",
      "youtube-dl==2021.12.17\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "# Requirements from your list\n",
    "requirements = [\n",
    "    \"absl-py==2.1.0\",\n",
    "    \"accelerate==0.31.0\",\n",
    "    \"aiohttp==3.9.1\",\n",
    "    \"aiosignal==1.3.1\",\n",
    "    \"alembic==1.13.1\",\n",
    "    \"annotated-types==0.6.0\",\n",
    "    \"antlr4-python3-runtime==4.9.3\",\n",
    "    \"anyio==4.2.0\",\n",
    "    \"asteroid-filterbanks==0.4.0\",\n",
    "    \"async-timeout==4.0.3\",\n",
    "    \"attrs==23.2.0\",\n",
    "    \"audioread==3.0.1\",\n",
    "    \"certifi==2023.11.17\",\n",
    "    \"cffi==1.16.0\",\n",
    "    \"charset-normalizer==3.3.2\",\n",
    "    \"click==8.1.7\",\n",
    "    \"colorama==0.4.6\",\n",
    "    \"colorlog==6.8.0\",\n",
    "    \"contourpy==1.2.0\",\n",
    "    \"cycler==0.12.1\",\n",
    "    \"decorator==4.4.2\",\n",
    "    \"decord==0.6.0\",\n",
    "    \"deepspeed==0.14.3\",\n",
    "    \"distro==1.9.0\",\n",
    "    \"docopt==0.6.2\",\n",
    "    \"einops==0.7.0\",\n",
    "    \"exceptiongroup==1.2.0\",\n",
    "    \"filelock==3.13.1\",\n",
    "    \"fonttools==4.47.2\",\n",
    "    \"frozenlist==1.4.1\",\n",
    "    \"fsspec==2023.12.2\",\n",
    "    \"greenlet==3.0.3\",\n",
    "    \"grpcio==1.63.0\",\n",
    "    \"h11==0.14.0\",\n",
    "    \"h5py==3.11.0\",\n",
    "    \"hjson==3.1.0\",\n",
    "    \"httpcore==1.0.2\",\n",
    "    \"httpx==0.26.0\",\n",
    "    \"huggingface-hub==0.23.4\",\n",
    "    \"HyperPyYAML==1.2.2\",\n",
    "    \"idna==3.6\",\n",
    "    \"imageio==2.34.1\",\n",
    "    \"imageio-ffmpeg==0.5.1\",\n",
    "    \"importlib-resources==6.1.1\",\n",
    "    \"importlib_metadata==7.1.0\",\n",
    "    \"Jinja2==3.1.3\",\n",
    "    \"joblib==1.3.2\",\n",
    "    \"julius==0.2.7\",\n",
    "    \"kiwisolver==1.4.5\",\n",
    "    \"lazy_loader==0.3\",\n",
    "    \"librosa==0.10.1\",\n",
    "    \"lightning==2.1.3\",\n",
    "    \"lightning-utilities==0.10.1\",\n",
    "    \"llvmlite==0.41.1\",\n",
    "    \"Mako==1.3.0\",\n",
    "    \"Markdown==3.6\",\n",
    "    \"markdown-it-py==3.0.0\",\n",
    "    \"MarkupSafe==2.1.4\",\n",
    "    \"matplotlib==3.8.2\",\n",
    "    \"mdurl==0.1.2\",\n",
    "    \"more-itertools==10.2.0\",\n",
    "    \"moviepy==1.0.3\",\n",
    "    \"mpmath==1.3.0\",\n",
    "    \"msgpack==1.0.7\",\n",
    "    \"multidict==6.0.4\",\n",
    "    \"networkx==3.2.1\",\n",
    "    \"ninja==1.11.1.1\",\n",
    "    \"numba==0.58.1\",\n",
    "    \"numpy==1.26.3\",\n",
    "    \"nvidia-cublas-cu12==12.1.3.1\",\n",
    "    \"nvidia-cuda-cupti-cu12==12.1.105\",\n",
    "    \"nvidia-cuda-nvrtc-cu12==12.1.105\",\n",
    "    \"nvidia-cuda-runtime-cu12==12.1.105\",\n",
    "    \"nvidia-cudnn-cu12==8.9.2.26\",\n",
    "    \"nvidia-cufft-cu12==11.0.2.54\",\n",
    "    \"nvidia-curand-cu12==10.3.2.106\",\n",
    "    \"nvidia-cusolver-cu12==11.4.5.107\",\n",
    "    \"nvidia-cusparse-cu12==12.1.0.106\",\n",
    "    \"nvidia-ml-py==12.555.43\",\n",
    "    \"nvidia-nccl-cu12==2.18.1\",\n",
    "    \"nvidia-nvjitlink-cu12==12.3.101\",\n",
    "    \"nvidia-nvtx-cu12==12.1.105\",\n",
    "    \"omegaconf==2.3.0\",\n",
    "    \"openai==1.9.0\",\n",
    "    \"openai-whisper==20231117\",\n",
    "    \"opencv-python==4.9.0.80\",\n",
    "    \"optuna==3.5.0\",\n",
    "    \"packaging==23.2\",\n",
    "    \"pandas==2.2.0\",\n",
    "    \"peft==0.3.0\",\n",
    "    \"pillow==10.2.0\",\n",
    "    \"platformdirs==4.1.0\",\n",
    "    \"pooch==1.8.0\",\n",
    "    \"primePy==1.3\",\n",
    "    \"proglog==0.1.10\",\n",
    "    \"protobuf==4.25.2\",\n",
    "    \"psutil==6.0.0\",\n",
    "    \"py-cpuinfo==9.0.0\",\n",
    "    \"pyannote.core==5.0.0\",\n",
    "    \"pyannote.database==5.0.1\",\n",
    "    \"pyannote.metrics==3.2.1\",\n",
    "    \"pyannote.pipeline==3.0.1\",\n",
    "    \"pycparser==2.21\",\n",
    "    \"pydantic==2.5.3\",\n",
    "    \"pydantic_core==2.14.6\",\n",
    "    \"Pygments==2.17.2\",\n",
    "    \"pyparsing==3.1.1\",\n",
    "    \"python-dateutil==2.8.2\",\n",
    "    \"pytorch-lightning==2.1.3\",\n",
    "    \"pytorch-metric-learning==2.4.1\",\n",
    "    \"pytube==15.0.0\",\n",
    "    \"pytz==2023.3.post1\",\n",
    "    \"PyYAML==6.0.1\",\n",
    "    \"regex==2023.12.25\",\n",
    "    \"requests==2.31.0\",\n",
    "    \"rich==13.7.0\",\n",
    "    \"ruamel.yaml==0.18.5\",\n",
    "    \"ruamel.yaml.clib==0.2.8\",\n",
    "    \"safetensors==0.4.3\",\n",
    "    \"scikit-learn==1.4.0\",\n",
    "    \"scipy==1.11.4\",\n",
    "    \"semver==3.0.2\",\n",
    "    \"sentencepiece==0.1.99\",\n",
    "    \"shellingham==1.5.4\",\n",
    "    \"six==1.16.0\",\n",
    "    \"sniffio==1.3.0\",\n",
    "    \"sortedcontainers==2.4.0\",\n",
    "    \"soundfile==0.12.1\",\n",
    "    \"soxr==0.3.7\",\n",
    "    \"speechbrain==0.5.16\",\n",
    "    \"SQLAlchemy==2.0.25\",\n",
    "    \"sympy==1.12\",\n",
    "    \"tabulate==0.9.0\",\n",
    "    \"tensorboard==2.16.2\",\n",
    "    \"tensorboard-data-server==0.7.2\",\n",
    "    \"tensorboardX==2.6.2.2\",\n",
    "    \"threadpoolctl==3.2.0\",\n",
    "    \"tiktoken==0.5.2\",\n",
    "    \"timm==0.9.12\",\n",
    "    \"tokenizers==0.19.1\",\n",
    "    \"torch==1.13.1+cu116\",\n",
    "    \"torch-audiomentations==0.11.0\",\n",
    "    \"torch-pitch-shift==1.2.4\",\n",
    "    \"torchaudio==0.13.1+cu116\",\n",
    "    \"torchmetrics==1.3.0.post0\",\n",
    "    \"torchvision==0.14.1+cu116\",\n",
    "    \"tqdm==4.66.1\",\n",
    "    \"transformers==4.41.2\",\n",
    "    \"triton==2.1.0\",\n",
    "    \"typer==0.9.0\",\n",
    "    \"typing_extensions==4.9.0\",\n",
    "    \"tzdata==2023.4\",\n",
    "    \"urllib3==2.1.0\",\n",
    "    \"Werkzeug==3.0.3\",\n",
    "    \"yarl==1.9.4\",\n",
    "    \"youtube-dl==2021.12.17\",\n",
    "    \"zipp==3.17.0\"\n",
    "]\n",
    "\n",
    "# Get installed packages\n",
    "installed_packages = {pkg.key for pkg in pkg_resources.working_set}\n",
    "\n",
    "# Identify missing packages\n",
    "missing_packages = [pkg for pkg in requirements if pkg.split('==')[0] not in installed_packages]\n",
    "\n",
    "# Display missing packages\n",
    "print(\"Missing Packages:\")\n",
    "for pkg in missing_packages:\n",
    "    print(pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea6c11eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:52:38.476973Z",
     "iopub.status.busy": "2025-03-19T11:52:38.476697Z",
     "iopub.status.idle": "2025-03-19T11:53:35.116227Z",
     "shell.execute_reply": "2025-03-19T11:53:35.115136Z"
    },
    "papermill": {
     "duration": 56.646451,
     "end_time": "2025-03-19T11:53:35.117939",
     "exception": false,
     "start_time": "2025-03-19T11:52:38.471488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.1 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\r\n",
      "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 2.5.3 which is incompatible.\r\n",
      "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.9.0 which is incompatible.\r\n",
      "flask 3.1.0 requires Werkzeug>=3.1, but you have werkzeug 3.0.3 which is incompatible.\r\n",
      "fury 0.12.0 requires lazy-loader>=0.4, but you have lazy-loader 0.3 which is incompatible.\r\n",
      "langchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\r\n",
      "langchain 0.3.12 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 2.5.3 which is incompatible.\r\n",
      "scikit-image 0.25.0 requires lazy-loader>=0.4, but you have lazy-loader 0.3 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\r\n",
      "typeguard 4.4.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.9.0 which is incompatible.\r\n",
      "wandb 0.19.1 requires pydantic<3,>=2.6, but you have pydantic 2.5.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Instead of run :\n",
    "# pip install -r requirements.txt\n",
    "# We JUST need to run these 2 BELOW CELLS\n",
    "\n",
    "! pip install antlr4-python3-runtime==4.9.3 \\\n",
    "    asteroid-filterbanks==0.4.0 \\\n",
    "    decord==0.6.0 \\\n",
    "    deepspeed>=0.9.0 \\\n",
    "    einops==0.7.0 \\\n",
    "    hjson==3.1.0 \\\n",
    "    HyperPyYAML==1.2.2 \\\n",
    "    imageio-ffmpeg==0.5.1 \\\n",
    "    importlib_metadata==7.1.0 \\\n",
    "    Jinja2==3.1.3 \\\n",
    "    julius==0.2.7 \\\n",
    "    lazy_loader==0.3 \\\n",
    "    lightning==2.1.3 \\\n",
    "    Mako==1.3.0 \\\n",
    "    Markdown==3.6 \\\n",
    "    MarkupSafe==2.1.4 \\\n",
    "    moviepy==1.0.3 \\\n",
    "    omegaconf==2.3.0 \\\n",
    "    openai==1.9.0 \\\n",
    "    openai-whisper==20231117 \\\n",
    "    peft>=0.5.0 \\\n",
    "    primePy==1.3 \\\n",
    "    proglog==0.1.10 \\\n",
    "    pyannote.core==5.0.0 \\\n",
    "    pyannote.database==5.0.1 \\\n",
    "    pyannote.metrics==3.2.1 \\\n",
    "    pyannote.pipeline==3.0.1 \\\n",
    "    pydantic_core==2.14.6 \\\n",
    "    Pygments==2.17.2 \\\n",
    "    pytorch-metric-learning==2.4.1 \\\n",
    "    pytube==15.0.0 \\\n",
    "    PyYAML==6.0.1 \\\n",
    "    speechbrain==0.5.16 \\\n",
    "    SQLAlchemy==2.0.25 \\\n",
    "    tensorboardX==2.6.2.2 \\\n",
    "    tiktoken==0.5.2 \\\n",
    "    torch-audiomentations==0.11.0 \\\n",
    "    torch-pitch-shift==1.2.4 \\\n",
    "    triton==2.1.0 \\\n",
    "    typing_extensions==4.9.0 \\\n",
    "    Werkzeug==3.0.3 \\\n",
    "    youtube-dl==2021.12.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a70cdf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:53:35.128998Z",
     "iopub.status.busy": "2025-03-19T11:53:35.128696Z",
     "iopub.status.idle": "2025-03-19T11:55:17.419854Z",
     "shell.execute_reply": "2025-03-19T11:55:17.418686Z"
    },
    "papermill": {
     "duration": 102.298538,
     "end_time": "2025-03-19T11:55:17.421551",
     "exception": false,
     "start_time": "2025-03-19T11:53:35.123013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: antlr4-python3-runtime==4.9.3 in /usr/local/lib/python3.10/dist-packages (4.9.3)\r\n",
      "Requirement already satisfied: asteroid-filterbanks==0.4.0 in /usr/local/lib/python3.10/dist-packages (0.4.0)\r\n",
      "Requirement already satisfied: decord==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\r\n",
      "Collecting deepspeed==0.14.3\r\n",
      "  Downloading deepspeed-0.14.3.tar.gz (1.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: einops==0.7.0 in /usr/local/lib/python3.10/dist-packages (0.7.0)\r\n",
      "Requirement already satisfied: hjson==3.1.0 in /usr/local/lib/python3.10/dist-packages (3.1.0)\r\n",
      "Requirement already satisfied: HyperPyYAML==1.2.2 in /usr/local/lib/python3.10/dist-packages (1.2.2)\r\n",
      "Requirement already satisfied: imageio-ffmpeg==0.5.1 in /usr/local/lib/python3.10/dist-packages (0.5.1)\r\n",
      "Requirement already satisfied: importlib_metadata==7.1.0 in /usr/local/lib/python3.10/dist-packages (7.1.0)\r\n",
      "Requirement already satisfied: Jinja2==3.1.3 in /usr/local/lib/python3.10/dist-packages (3.1.3)\r\n",
      "Requirement already satisfied: julius==0.2.7 in /usr/local/lib/python3.10/dist-packages (0.2.7)\r\n",
      "Requirement already satisfied: lazy_loader==0.3 in /usr/local/lib/python3.10/dist-packages (0.3)\r\n",
      "Requirement already satisfied: lightning==2.1.3 in /usr/local/lib/python3.10/dist-packages (2.1.3)\r\n",
      "Requirement already satisfied: Mako==1.3.0 in /usr/local/lib/python3.10/dist-packages (1.3.0)\r\n",
      "Requirement already satisfied: Markdown==3.6 in /usr/local/lib/python3.10/dist-packages (3.6)\r\n",
      "Requirement already satisfied: MarkupSafe==2.1.4 in /usr/local/lib/python3.10/dist-packages (2.1.4)\r\n",
      "Requirement already satisfied: moviepy==1.0.3 in /usr/local/lib/python3.10/dist-packages (1.0.3)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.18.1\r\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.3.101\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.10/dist-packages (2.3.0)\r\n",
      "Requirement already satisfied: openai==1.9.0 in /usr/local/lib/python3.10/dist-packages (1.9.0)\r\n",
      "Requirement already satisfied: openai-whisper==20231117 in /usr/local/lib/python3.10/dist-packages (20231117)\r\n",
      "Collecting peft==0.3.0\r\n",
      "  Downloading peft-0.3.0-py3-none-any.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: primePy==1.3 in /usr/local/lib/python3.10/dist-packages (1.3)\r\n",
      "Requirement already satisfied: proglog==0.1.10 in /usr/local/lib/python3.10/dist-packages (0.1.10)\r\n",
      "Requirement already satisfied: pyannote.core==5.0.0 in /usr/local/lib/python3.10/dist-packages (5.0.0)\r\n",
      "Requirement already satisfied: pyannote.database==5.0.1 in /usr/local/lib/python3.10/dist-packages (5.0.1)\r\n",
      "Requirement already satisfied: pyannote.metrics==3.2.1 in /usr/local/lib/python3.10/dist-packages (3.2.1)\r\n",
      "Requirement already satisfied: pyannote.pipeline==3.0.1 in /usr/local/lib/python3.10/dist-packages (3.0.1)\r\n",
      "Requirement already satisfied: pydantic_core==2.14.6 in /usr/local/lib/python3.10/dist-packages (2.14.6)\r\n",
      "Requirement already satisfied: Pygments==2.17.2 in /usr/local/lib/python3.10/dist-packages (2.17.2)\r\n",
      "Requirement already satisfied: pytorch-metric-learning==2.4.1 in /usr/local/lib/python3.10/dist-packages (2.4.1)\r\n",
      "Requirement already satisfied: pytube==15.0.0 in /usr/local/lib/python3.10/dist-packages (15.0.0)\r\n",
      "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (6.0.1)\r\n",
      "Requirement already satisfied: speechbrain==0.5.16 in /usr/local/lib/python3.10/dist-packages (0.5.16)\r\n",
      "Requirement already satisfied: SQLAlchemy==2.0.25 in /usr/local/lib/python3.10/dist-packages (2.0.25)\r\n",
      "Requirement already satisfied: tensorboardX==2.6.2.2 in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\r\n",
      "Requirement already satisfied: tiktoken==0.5.2 in /usr/local/lib/python3.10/dist-packages (0.5.2)\r\n",
      "Requirement already satisfied: torch-audiomentations==0.11.0 in /usr/local/lib/python3.10/dist-packages (0.11.0)\r\n",
      "Requirement already satisfied: torch-pitch-shift==1.2.4 in /usr/local/lib/python3.10/dist-packages (1.2.4)\r\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0)\r\n",
      "Requirement already satisfied: typing_extensions==4.9.0 in /usr/local/lib/python3.10/dist-packages (4.9.0)\r\n",
      "Requirement already satisfied: Werkzeug==3.0.3 in /usr/local/lib/python3.10/dist-packages (3.0.3)\r\n",
      "Requirement already satisfied: youtube-dl==2021.12.17 in /usr/local/lib/python3.10/dist-packages (2021.12.17)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from asteroid-filterbanks==0.4.0) (1.26.4)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from asteroid-filterbanks==0.4.0) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3) (1.11.1.3)\r\n",
      "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3) (12.570.86)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3) (24.2)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3) (5.9.5)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3) (9.0.0)\r\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3) (2.5.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.3) (4.67.1)\r\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from HyperPyYAML==1.2.2) (0.18.10)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg==0.5.1) (75.1.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata==7.1.0) (3.21.0)\r\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning==2.1.3) (2024.12.0)\r\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1.3) (0.12.0)\r\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1.3) (1.6.1)\r\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning==2.1.3) (2.5.0.post0)\r\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.3) (4.4.2)\r\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.3) (2.36.1)\r\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.3) (2.32.3)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.9.0) (3.7.1)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.9.0) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.9.0) (0.28.1)\r\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.9.0) (1.3.1)\r\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.60.0)\r\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.5.0)\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0) (4.47.0)\r\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft==0.3.0) (1.2.1)\r\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core==5.0.0) (2.4.0)\r\n",
      "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.core==5.0.0) (1.13.1)\r\n",
      "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pyannote.database==5.0.1) (2.2.3)\r\n",
      "Requirement already satisfied: typer>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]>=0.2.1->pyannote.database==5.0.1) (0.15.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics==3.2.1) (1.2.2)\r\n",
      "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics==3.2.1) (0.6.2)\r\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics==3.2.1) (0.9.0)\r\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics==3.2.1) (3.7.5)\r\n",
      "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics==3.2.1) (1.13.1)\r\n",
      "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.pipeline==3.0.1) (4.2.1)\r\n",
      "Requirement already satisfied: filelock>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from pyannote.pipeline==3.0.1) (3.17.0)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (1.4.2)\r\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (0.2.0)\r\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from speechbrain==0.5.16) (0.29.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy==2.0.25) (3.1.1)\r\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX==2.6.2.2) (3.20.3)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.2) (2024.11.6)\r\n",
      "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations==0.11.0) (0.10.2.post1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.9.0) (3.10)\r\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.9.0) (1.2.2)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning==2.1.3) (3.11.12)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.9.0) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.9.0) (1.0.7)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.9.0) (0.14.0)\r\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy==1.0.3) (11.0.0)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (3.0.1)\r\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.12.1)\r\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.5.0.post1)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.1.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics==3.2.1) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics==3.2.1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics==3.2.1) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics==3.2.1) (1.4.7)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics==3.2.1) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics==3.2.1) (2.9.0.post0)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->asteroid-filterbanks==0.4.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->asteroid-filterbanks==0.4.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->asteroid-filterbanks==0.4.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->asteroid-filterbanks==0.4.0) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->asteroid-filterbanks==0.4.0) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->asteroid-filterbanks==0.4.0) (2.4.1)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline==3.0.1) (1.14.1)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline==3.0.1) (6.9.0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database==5.0.1) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database==5.0.1) (2025.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.3) (0.7.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.4.1)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2.3.0)\r\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->HyperPyYAML==1.2.2) (0.2.12)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics==3.2.1) (3.5.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.1->pyannote.metrics==3.2.1) (1.3.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->asteroid-filterbanks==0.4.0) (3.4.2)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.2.1->typer[all]>=0.2.1->pyannote.database==5.0.1) (8.1.7)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.2.1->typer[all]>=0.2.1->pyannote.database==5.0.1) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.2.1->typer[all]>=0.2.1->pyannote.database==5.0.1) (13.9.4)\r\n",
      "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate->peft==0.3.0) (0.4.5)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.3.0) (0.21.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.1.3) (2.4.6)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.1.3) (1.3.2)\r\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.1.3) (5.0.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.1.3) (25.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.1.3) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.1.3) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.1.3) (0.2.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning==2.1.3) (1.18.3)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (4.3.6)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics==3.2.1) (1.17.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.2.1->typer[all]>=0.2.1->pyannote.database==5.0.1) (3.0.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (1.17.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->asteroid-filterbanks==0.4.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->asteroid-filterbanks==0.4.0) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->asteroid-filterbanks==0.4.0) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->asteroid-filterbanks==0.4.0) (2024.2.0)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.22)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->asteroid-filterbanks==0.4.0) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.2.1->typer[all]>=0.2.1->pyannote.database==5.0.1) (0.1.2)\r\n",
      "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading peft-0.3.0-py3-none-any.whl (56 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: deepspeed\r\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for deepspeed: filename=deepspeed-0.14.3-py3-none-any.whl size=1443090 sha256=c25d92045f5566ea5ee4571b91a7f038a37e048ae770faa6f044b5d24805deb5\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/82/bb/60/29f264d7ca7f5f2f3c9c1a6275883578977c0f608f1dee0790\r\n",
      "Successfully built deepspeed\r\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, peft, deepspeed\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\r\n",
      "  Attempting uninstall: peft\r\n",
      "    Found existing installation: peft 0.14.0\r\n",
      "    Uninstalling peft-0.14.0:\r\n",
      "      Successfully uninstalled peft-0.14.0\r\n",
      "  Attempting uninstall: deepspeed\r\n",
      "    Found existing installation: deepspeed 0.16.4\r\n",
      "    Uninstalling deepspeed-0.16.4:\r\n",
      "      Successfully uninstalled deepspeed-0.16.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed deepspeed-0.14.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 peft-0.3.0\r\n"
     ]
    }
   ],
   "source": [
    "# List of missing packages to install\n",
    "missing_packages = [\n",
    "    \"antlr4-python3-runtime==4.9.3\",\n",
    "    \"asteroid-filterbanks==0.4.0\",\n",
    "    \"decord==0.6.0\",\n",
    "    \"deepspeed==0.14.3\",\n",
    "    \"einops==0.7.0\",\n",
    "    \"hjson==3.1.0\",\n",
    "    \"HyperPyYAML==1.2.2\",\n",
    "    \"imageio-ffmpeg==0.5.1\",\n",
    "    \"importlib_metadata==7.1.0\",\n",
    "    \"Jinja2==3.1.3\",\n",
    "    \"julius==0.2.7\",\n",
    "    \"lazy_loader==0.3\",\n",
    "    \"lightning==2.1.3\",\n",
    "    \"Mako==1.3.0\",\n",
    "    \"Markdown==3.6\",\n",
    "    \"MarkupSafe==2.1.4\",\n",
    "    \"moviepy==1.0.3\",\n",
    "    \"nvidia-cublas-cu12==12.1.3.1\",\n",
    "    \"nvidia-cuda-cupti-cu12==12.1.105\",\n",
    "    \"nvidia-cuda-nvrtc-cu12==12.1.105\",\n",
    "    \"nvidia-cuda-runtime-cu12==12.1.105\",\n",
    "    \"nvidia-cudnn-cu12==8.9.2.26\",\n",
    "    \"nvidia-cufft-cu12==11.0.2.54\",\n",
    "    \"nvidia-curand-cu12==10.3.2.106\",\n",
    "    \"nvidia-cusolver-cu12==11.4.5.107\",\n",
    "    \"nvidia-cusparse-cu12==12.1.0.106\",\n",
    "    \"nvidia-nccl-cu12==2.18.1\",\n",
    "    \"nvidia-nvjitlink-cu12==12.3.101\",\n",
    "    \"nvidia-nvtx-cu12==12.1.105\",\n",
    "    \"omegaconf==2.3.0\",\n",
    "    \"openai==1.9.0\",\n",
    "    \"openai-whisper==20231117\",\n",
    "    \"peft==0.3.0\",\n",
    "    \"primePy==1.3\",\n",
    "    \"proglog==0.1.10\",\n",
    "    \"pyannote.core==5.0.0\",\n",
    "    \"pyannote.database==5.0.1\",\n",
    "    \"pyannote.metrics==3.2.1\",\n",
    "    \"pyannote.pipeline==3.0.1\",\n",
    "    \"pydantic_core==2.14.6\",\n",
    "    \"Pygments==2.17.2\",\n",
    "    \"pytorch-metric-learning==2.4.1\",\n",
    "    \"pytube==15.0.0\",\n",
    "    \"PyYAML==6.0.1\",\n",
    "    \"speechbrain==0.5.16\",\n",
    "    \"SQLAlchemy==2.0.25\",\n",
    "    \"tensorboardX==2.6.2.2\",\n",
    "    \"tiktoken==0.5.2\",\n",
    "    \"torch-audiomentations==0.11.0\",\n",
    "    \"torch-pitch-shift==1.2.4\",\n",
    "    \"triton==2.1.0\",\n",
    "    \"typing_extensions==4.9.0\",\n",
    "    \"Werkzeug==3.0.3\",\n",
    "    \"youtube-dl==2021.12.17\"\n",
    "]\n",
    "\n",
    "# Install missing packages\n",
    "!pip install {' '.join(missing_packages)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ced040",
   "metadata": {
    "papermill": {
     "duration": 0.035446,
     "end_time": "2025-03-19T11:55:17.493019",
     "exception": false,
     "start_time": "2025-03-19T11:55:17.457573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Install this Cuda Version to get rid of Freezeing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f9cd67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:55:17.563932Z",
     "iopub.status.busy": "2025-03-19T11:55:17.563667Z",
     "iopub.status.idle": "2025-03-19T11:56:57.996087Z",
     "shell.execute_reply": "2025-03-19T11:56:57.994966Z"
    },
    "papermill": {
     "duration": 100.469892,
     "end_time": "2025-03-19T11:56:57.997834",
     "exception": false,
     "start_time": "2025-03-19T11:55:17.527942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly[and-cuda]\r\n",
      "  Downloading tf_nightly-2.20.0.dev20250318-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (24.2)\r\n",
      "Collecting protobuf<6.0.0dev,>=4.21.6 (from tf-nightly[and-cuda])\r\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (75.1.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (4.9.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (1.17.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (1.68.1)\r\n",
      "Collecting tb-nightly~=2.19.0.a (from tf-nightly[and-cuda])\r\n",
      "  Downloading tb_nightly-2.19.0a20250218-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Collecting keras-nightly>=3.6.0.dev (from tf-nightly[and-cuda])\r\n",
      "  Downloading keras_nightly-3.9.0.dev2025031903-py3-none-any.whl.metadata (6.1 kB)\r\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (1.26.4)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly[and-cuda]) (3.12.1)\r\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tf-nightly[and-cuda])\r\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.5.3.2 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_cublas_cu12-12.5.3.2-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.5.82 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.5.82 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.5.82 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.5.82 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.3.0.75 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_cudnn_cu12-9.3.0.75-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.3.61 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.3.61-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.6.82 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_curand_cu12-10.3.6.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.3.83 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.3.83-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.5.1.3 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_cusparse_cu12-12.5.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.25.1 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_nccl_cu12-2.25.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.5.82 (from tf-nightly[and-cuda])\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tf-nightly[and-cuda]) (0.45.1)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly[and-cuda]) (13.9.4)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly[and-cuda]) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly[and-cuda]) (0.13.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.2.0,>=1.26.0->tf-nightly[and-cuda]) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.2.0,>=1.26.0->tf-nightly[and-cuda]) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.2.0,>=1.26.0->tf-nightly[and-cuda]) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.2.0,>=1.26.0->tf-nightly[and-cuda]) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.2.0,>=1.26.0->tf-nightly[and-cuda]) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.2.0,>=1.26.0->tf-nightly[and-cuda]) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly[and-cuda]) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly[and-cuda]) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly[and-cuda]) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tf-nightly[and-cuda]) (2025.1.31)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly[and-cuda]) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly[and-cuda]) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly[and-cuda]) (3.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.19.0.a->tf-nightly[and-cuda]) (2.1.4)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.2.0,>=1.26.0->tf-nightly[and-cuda]) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.2.0,>=1.26.0->tf-nightly[and-cuda]) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.2.0,>=1.26.0->tf-nightly[and-cuda]) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.2.0,>=1.26.0->tf-nightly[and-cuda]) (2024.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly[and-cuda]) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly[and-cuda]) (2.17.2)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.2.0,>=1.26.0->tf-nightly[and-cuda]) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nightly>=3.6.0.dev->tf-nightly[and-cuda]) (0.1.2)\r\n",
      "Downloading nvidia_cublas_cu12-12.5.3.2-py3-none-manylinux2014_x86_64.whl (363.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.3/363.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (22.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (24.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (895 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.7/895.7 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.3.0.75-py3-none-manylinux2014_x86_64.whl (577.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.2/577.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.3.61-py3-none-manylinux2014_x86_64.whl (192.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.6.82-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.3.83-py3-none-manylinux2014_x86_64.whl (130.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.1.3-py3-none-manylinux2014_x86_64.whl (217.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.6/217.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.25.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading keras_nightly-3.9.0.dev2025031903-py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tb_nightly-2.19.0a20250218-py3-none-any.whl (5.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tf_nightly-2.20.0.dev20250318-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (654.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m654.7/654.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: protobuf, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ml-dtypes, tb-nightly, keras-nightly, tf-nightly\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.3.101\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.3.101:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.3.101\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.18.1\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.18.1:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\r\n",
      "  Attempting uninstall: nvidia-cuda-nvcc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvcc-cu12 12.6.85\r\n",
      "    Uninstalling nvidia-cuda-nvcc-cu12-12.6.85:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvcc-cu12-12.6.85\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\r\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\r\n",
      "  Attempting uninstall: ml-dtypes\r\n",
      "    Found existing installation: ml-dtypes 0.4.1\r\n",
      "    Uninstalling ml-dtypes-0.4.1:\r\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "tensorflow 2.17.1 requires ml-dtypes<0.5.0,>=0.3.1, but you have ml-dtypes 0.5.1 which is incompatible.\r\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\r\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\r\n",
      "wandb 0.19.1 requires pydantic<3,>=2.6, but you have pydantic 2.5.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed keras-nightly-3.9.0.dev2025031903 ml-dtypes-0.5.1 nvidia-cublas-cu12-12.5.3.2 nvidia-cuda-cupti-cu12-12.5.82 nvidia-cuda-nvcc-cu12-12.5.82 nvidia-cuda-nvrtc-cu12-12.5.82 nvidia-cuda-runtime-cu12-12.5.82 nvidia-cudnn-cu12-9.3.0.75 nvidia-cufft-cu12-11.2.3.61 nvidia-curand-cu12-10.3.6.82 nvidia-cusolver-cu12-11.6.3.83 nvidia-cusparse-cu12-12.5.1.3 nvidia-nccl-cu12-2.25.1 nvidia-nvjitlink-cu12-12.5.82 protobuf-5.29.3 tb-nightly-2.19.0a20250218 tf-nightly-2.20.0.dev20250318\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-nightly[and-cuda]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9b0ef",
   "metadata": {
    "papermill": {
     "duration": 0.106361,
     "end_time": "2025-03-19T11:56:58.173660",
     "exception": false,
     "start_time": "2025-03-19T11:56:58.067299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Move code to ***kaggle/working*** dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c215f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:56:58.310936Z",
     "iopub.status.busy": "2025-03-19T11:56:58.310628Z",
     "iopub.status.idle": "2025-03-19T11:56:58.819506Z",
     "shell.execute_reply": "2025-03-19T11:56:58.818458Z"
    },
    "papermill": {
     "duration": 0.579093,
     "end_time": "2025-03-19T11:56:58.821046",
     "exception": false,
     "start_time": "2025-03-19T11:56:58.241953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/sample-level-multimodal-level-multimodal-learning /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cfcbd01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:56:58.958355Z",
     "iopub.status.busy": "2025-03-19T11:56:58.958088Z",
     "iopub.status.idle": "2025-03-19T11:56:58.964385Z",
     "shell.execute_reply": "2025-03-19T11:56:58.963711Z"
    },
    "papermill": {
     "duration": 0.076259,
     "end_time": "2025-03-19T11:56:58.965627",
     "exception": false,
     "start_time": "2025-03-19T11:56:58.889368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/sample-level-multimodal-level-multimodal-learning/code\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/sample-level-multimodal-level-multimodal-learning/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5ba648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:56:59.100912Z",
     "iopub.status.busy": "2025-03-19T11:56:59.100687Z",
     "iopub.status.idle": "2025-03-19T11:56:59.103737Z",
     "shell.execute_reply": "2025-03-19T11:56:59.103066Z"
    },
    "papermill": {
     "duration": 0.071801,
     "end_time": "2025-03-19T11:56:59.104931",
     "exception": false,
     "start_time": "2025-03-19T11:56:59.033130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cat /kaggle/working/sample-level-multimodal-level-multimodal-learning/code/sample_level.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba90386",
   "metadata": {
    "papermill": {
     "duration": 0.066756,
     "end_time": "2025-03-19T11:56:59.239291",
     "exception": false,
     "start_time": "2025-03-19T11:56:59.172535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Modify dataloader.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c63a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:56:59.375718Z",
     "iopub.status.busy": "2025-03-19T11:56:59.375461Z",
     "iopub.status.idle": "2025-03-19T11:56:59.382161Z",
     "shell.execute_reply": "2025-03-19T11:56:59.381474Z"
    },
    "papermill": {
     "duration": 0.076032,
     "end_time": "2025-03-19T11:56:59.383274",
     "exception": false,
     "start_time": "2025-03-19T11:56:59.307242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/sample-level-multimodal-level-multimodal-learning/code/datasets/dataloader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/sample-level-multimodal-level-multimodal-learning/code/datasets/dataloader.py\n",
    "\n",
    "import json\n",
    "import h5py\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import io\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import csv\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import pdb\n",
    "\n",
    "\n",
    "class CramedDataset(Dataset):\n",
    "\n",
    "    def __init__(self, mode, args):\n",
    "        self.args = args\n",
    "        self.image = []\n",
    "        self.audio = []\n",
    "        self.label = []\n",
    "        self.mode = mode\n",
    "\n",
    "        self.data_root = './datasets'\n",
    "        class_dict = {'NEU':0, 'HAP':1, 'SAD':2, 'FEA':3, 'DIS':4, 'ANG':5}\n",
    "\n",
    "        self.visual_feature_path = args.visual_path\n",
    "        self.audio_feature_path = args.audio_path\n",
    "\n",
    "        self.train_csv = os.path.join(self.data_root, args.dataset + '/train.csv')\n",
    "        self.test_csv = os.path.join(self.data_root, args.dataset + '/test.csv')\n",
    "\n",
    "        if mode == 'train':\n",
    "            csv_file = self.train_csv\n",
    "        else:\n",
    "            csv_file = self.test_csv\n",
    "\n",
    "        with open(csv_file, encoding='UTF-8-sig') as f2:\n",
    "            csv_reader = csv.reader(f2)\n",
    "            for item in csv_reader:\n",
    "                audio_path = os.path.join(self.audio_feature_path, item[0] + '.wav')\n",
    "                visual_path = os.path.join(self.visual_feature_path, 'Image-{:02d}-FPS'.format(self.args.fps), item[0])\n",
    "\n",
    "                if os.path.exists(audio_path) and os.path.exists(visual_path):\n",
    "                    self.image.append(visual_path)\n",
    "                    self.audio.append(audio_path)\n",
    "                    self.label.append(class_dict[item[1]])\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # audio\n",
    "        samples, rate = librosa.load(self.audio[idx], sr=22050) # Sample rate = 22050 samples per second. We want discrete signal, so we sample from continuous/natural signal\n",
    "        resamples = np.tile(samples, 5)[:((299-1)*353+512)] # Each audio sample are repeated three times to ensure each signal length of at least 3 seconds \n",
    "        resamples[resamples > 1.] = 1.\n",
    "        resamples[resamples < -1.] = -1.\n",
    "\n",
    "        spectrogram = librosa.stft(resamples, n_fft=512, hop_length=353)\n",
    "        spectrogram = np.log(np.abs(spectrogram) + 1e-7)\n",
    "        #mean = np.mean(spectrogram)\n",
    "        #std = np.std(spectrogram)\n",
    "        #spectrogram = np.divide(spectrogram - mean, std + 1e-9)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(size=(224, 224)), # Keep the whole image\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(size=(224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "        # Visual\n",
    "        image_samples = os.listdir(self.image[idx])\n",
    "        select_index = np.random.choice(len(image_samples), size=self.args.fps, replace=False)\n",
    "        select_index.sort()\n",
    "        images = torch.zeros((self.args.fps, 3, 224, 224))# (T=1,C=3,H=224,W=224)\n",
    "        for i in range(self.args.fps): # fps = 1(defalt)\n",
    "            img = Image.open(os.path.join(self.image[idx], image_samples[i])).convert('RGB')\n",
    "            img = transform(img)\n",
    "            images[i] = img\n",
    "            \n",
    "        # Reshape images\n",
    "        # print(f\"Before Permute: {images.shape}\") # [1, 3, 224, 224]\n",
    "        images = torch.permute(images, (1,0,2,3)) # Reshape images=> (C=3,T=1,H=224,W=224) (Take multiple frames as inputs)\n",
    "        # print(f\"After Permute: {images.shape}\") # [3, 1, 224, 224]\n",
    "        \n",
    "        # label\n",
    "        label = self.label[idx]\n",
    "\n",
    "        # print(f\"Audio after Permute: {spectrogram.shape}\") # (257, 300)\n",
    "        \n",
    "        return images, spectrogram, label, idx\n",
    "\n",
    "\n",
    "\n",
    "class CramedDataset_sample_level(Dataset):\n",
    "\n",
    "    def __init__(self, mode, args, contribution):\n",
    "        self.args = args\n",
    "        self.image = []\n",
    "        self.audio = []\n",
    "        self.label = []\n",
    "        self.drop = []\n",
    "        self.sample_name = [] # Save the name of the samples\n",
    "        self.label_name = [] # Save the label name of each sample\n",
    "        self.mode = mode\n",
    "\n",
    "        self.data_root = './datasets'\n",
    "        class_dict = {'NEU':0, 'HAP':1, 'SAD':2, 'FEA':3, 'DIS':4, 'ANG':5}\n",
    "\n",
    "        self.visual_feature_path = args.visual_path\n",
    "        self.audio_feature_path = args.audio_path\n",
    "\n",
    "        self.train_csv = os.path.join(self.data_root, args.dataset + '/train.csv')\n",
    "        self.test_csv = os.path.join(self.data_root, args.dataset + '/test.csv')\n",
    "\n",
    "        if mode == 'train':\n",
    "            csv_file = self.train_csv\n",
    "        else:\n",
    "            csv_file = self.test_csv\n",
    "\n",
    "        with open(csv_file, encoding='UTF-8-sig') as f2:\n",
    "            csv_reader = csv.reader(f2)\n",
    "            for item in csv_reader:\n",
    "                audio_path = os.path.join(self.audio_feature_path, item[0] + '.wav')\n",
    "                visual_path = os.path.join(self.visual_feature_path, 'Image-{:02d}-FPS'.format(self.args.fps), item[0])\n",
    "\n",
    "                if os.path.exists(audio_path) and os.path.exists(visual_path):\n",
    "                    self.image.append(visual_path)\n",
    "                    self.audio.append(audio_path)\n",
    "                    self.label.append(class_dict[item[1]])\n",
    "                    self.sample_name.append(item[0])\n",
    "                    self.label_name.append(class_dict[item[1]])\n",
    "                    self.drop.append(0)\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "        print('Data reader finish')\n",
    "        length = len(self.audio) # The total number of samples(each (audio+visual) = a sample)\n",
    "\n",
    "        for i in range (length):\n",
    "            contri_a, contri_v = contribution[i] # contri_a=audio, contri_v=visual\n",
    "\n",
    "            # First, estimate+strengthen audio\n",
    "            if 0.4 < contri_a < 1: # audio contributes more than visual\n",
    "                for tt in range (1): # drop visual less (just 1 loop), or even not drop visual if neccessary\n",
    "                    self.image.append(os.path.join(self.visual_feature_path, 'Image-{:02d}-FPS'.format(self.args.fps), self.sample_name[i]))\n",
    "                    self.audio.append(os.path.join(self.audio_feature_path, self.sample_name[i] + '.wav'))\n",
    "                    self.label.append(self.label_name[i])\n",
    "                    self.drop.append(2) # we can choose drop visual or not \n",
    "            elif -0.1 < contri_a < 0.4: # audio contributes less\n",
    "                for tt in range(2): # drop visual more so that model depends on audio + update params\n",
    "                    self.image.append(os.path.join(self.visual_feature_path, 'Image-{:02d}-FPS'.format(self.args.fps), self.sample_name[i]))    \n",
    "                    self.audio.append(os.path.join(self.audio_feature_path, self.sample_name[i] + '.wav'))\n",
    "                    self.label.append(self.label_name[i])\n",
    "                    self.drop.append(2) \n",
    "            elif contri_a < -0.1: # audio contributes so weak, we need to drop visual heavily to strengthen audio\n",
    "                for tt in range(3):\n",
    "                    self.image.append(os.path.join(self.visual_feature_path, 'Image-{:02d}-FPS'.format(self.args.fps), self.sample_name[i]))    \n",
    "                    self.audio.append(os.path.join(self.audio_feature_path, self.sample_name[i] + '.wav'))\n",
    "                    self.label.append(self.label_name[i])\n",
    "                    self.drop.append(2)\n",
    "            \n",
    "            # Next, estimate+strengthen visual\n",
    "            if 0.4 < contri_v < 1: # visual contributes more than audio\n",
    "                for tt in range (1): # drop audio less (just 1 loop), or even not drop audio if neccessary\n",
    "                    self.image.append(os.path.join(self.visual_feature_path, 'Image-{:02d}-FPS'.format(self.args.fps), self.sample_name[i]))\n",
    "                    self.audio.append(os.path.join(self.audio_feature_path, self.sample_name[i] + '.wav'))\n",
    "                    self.label.append(self.label_name[i])\n",
    "                    self.drop.append(1) # we can choose drop audio or not \n",
    "            elif -0.1 < contri_v < 0.4: # viusual contributes less\n",
    "                for tt in range(2): # drop audio more so that model depends on visual + update params\n",
    "                    self.image.append(os.path.join(self.visual_feature_path, 'Image-{:02d}-FPS'.format(self.args.fps), self.sample_name[i]))    \n",
    "                    self.audio.append(os.path.join(self.audio_feature_path, self.sample_name[i] + '.wav'))\n",
    "                    self.label.append(self.label_name[i])\n",
    "                    self.drop.append(1) \n",
    "            elif contri_v < -0.1: # visual contributes so weak, we need to drop audio heavily to strengthen visual\n",
    "                for tt in range(3):\n",
    "                    self.image.append(os.path.join(self.visual_feature_path, 'Image-{:02d}-FPS'.format(self.args.fps), self.sample_name[i]))    \n",
    "                    self.audio.append(os.path.join(self.audio_feature_path, self.sample_name[i] + '.wav'))\n",
    "                    self.label.append(self.label_name[i])\n",
    "                    self.drop.append(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # audio\n",
    "        samples, rate = librosa.load(self.audio[idx], sr=22050) # Sample rate = 22050 samples per second. We want discrete signal, so we sample from continuous/natural signal\n",
    "        resamples = np.tile(samples, 5)[:((299-1)*353+512)] # Each audio sample are repeated three times to ensure each signal length of at least 3 seconds \n",
    "        resamples[resamples > 1.] = 1.\n",
    "        resamples[resamples < -1.] = -1.\n",
    "\n",
    "        spectrogram = librosa.stft(resamples, n_fft=512, hop_length=353)\n",
    "        spectrogram = np.log(np.abs(spectrogram) + 1e-7)\n",
    "        #mean = np.mean(spectrogram)\n",
    "        #std = np.std(spectrogram)\n",
    "        #spectrogram = np.divide(spectrogram - mean, std + 1e-9)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(size=(224, 224)), # Keep the whole image\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(size=(224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "        # Visual\n",
    "        image_samples = os.listdir(self.image[idx])\n",
    "        select_index = np.random.choice(len(image_samples), size=self.args.fps, replace=False)\n",
    "        select_index.sort()\n",
    "        images = torch.zeros((self.args.fps, 3, 224, 224))# (T=1,C=3,H=224,W=224)\n",
    "        for i in range(self.args.fps): # fps = 1(defalt)\n",
    "            img = Image.open(os.path.join(self.image[idx], image_samples[i])).convert('RGB')\n",
    "            img = transform(img)\n",
    "            images[i] = img\n",
    "            \n",
    "        # Reshape images\n",
    "        images = torch.permute(images, (1,0,2,3)) # Reshape images=> (C=3,T=1,H=224,W=224) (Take multiple frames as inputs)\n",
    "\n",
    "        # label and drop\n",
    "        label = self.label[idx]\n",
    "        drop = self.drop[idx]\n",
    "\n",
    "        return images, spectrogram, label, idx, drop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ea657",
   "metadata": {
    "papermill": {
     "duration": 0.067557,
     "end_time": "2025-03-19T11:56:59.519063",
     "exception": false,
     "start_time": "2025-03-19T11:56:59.451506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Change code in models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86a63599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:56:59.655021Z",
     "iopub.status.busy": "2025-03-19T11:56:59.654796Z",
     "iopub.status.idle": "2025-03-19T11:56:59.660005Z",
     "shell.execute_reply": "2025-03-19T11:56:59.659123Z"
    },
    "papermill": {
     "duration": 0.074575,
     "end_time": "2025-03-19T11:56:59.661266",
     "exception": false,
     "start_time": "2025-03-19T11:56:59.586691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/sample-level-multimodal-level-multimodal-learning/code/models/models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/sample-level-multimodal-level-multimodal-learning/code/models/models.py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from .backbone import resnet18\n",
    "\n",
    "class ConcatFusion(nn.Module):\n",
    "    def __init__(self, input_dim=1024, output_dim=100):\n",
    "        super(ConcatFusion, self).__init__()\n",
    "        self.fc_out = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, out):\n",
    "        # output = torch.cat((x, y), dim=1)\n",
    "        output = self.fc_out(out)\n",
    "        return output\n",
    "\n",
    "class AVClassifier(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(AVClassifier, self).__init__()\n",
    "\n",
    "        n_classes = args.n_classes\n",
    "\n",
    "        self.fusion_module = ConcatFusion(output_dim=n_classes)\n",
    "\n",
    "        self.audio_net = resnet18(modality='audio')\n",
    "        self.visual_net = resnet18(modality='visual')\n",
    "\n",
    "    def forward(self, audio, visual, drop = None, drop_arg = None):\n",
    "        # visual:[B,C,T,H,W]=[32,3,1,224,224];  audio:[B,C,H,W]=[32,1,257,300]\n",
    "        visual = visual.permute(0, 2, 1, 3, 4).contiguous() #[B,C,T,H,W] --> [B,T,C,H,W]\n",
    "        \n",
    "        a = self.audio_net(audio) #[B,C,H,W]\n",
    "        v = self.visual_net(visual) #[B,T,C,H,W] --> [B,new_C,new_H,new_W]\n",
    "        # print(f\"Audio after network: {a.shape}\") #[32, 512, 9, 10]\n",
    "        # print(f\"Visual after network: {v.shape}\") #[32, 512, 7, 7]\n",
    "\n",
    "        (_, C, H, W) = v.size()\n",
    "        B = a.size()[0]\n",
    "        v = v.reshape(B, -1, C, H, W)\n",
    "        v = v.permute(0, 2, 1, 3, 4)\n",
    "        # print(f\"Audio after reshape: {a.shape}\") #[32, 512, 9, 10]\n",
    "        # print(f\"Visual after reshape: {v.shape}\") #[32, 512, 1, 7, 7]\n",
    "\n",
    "        a = F.adaptive_avg_pool2d(a, 1)\n",
    "        v = F.adaptive_avg_pool3d(v, 1)\n",
    "\n",
    "        a = torch.flatten(a, 1)\n",
    "        v = torch.flatten(v, 1)\n",
    "        # print(f\"Audio after flatten: {a.shape}\") #[32, 512]\n",
    "        # print(f\"Visual after flaten: {v.shape}\") #[32, 512]\n",
    "\n",
    "        if drop_arg != None:\n",
    "            if self.__dict__['training'] and drop_arg.warmup == 0:\n",
    "                self.p = drop_arg.p\n",
    "                out, update_flag = self.execute_drop([a, v], self.p)\n",
    "                self.update = update_flag\n",
    "                self.update = torch.Tensor(self.update).cuda()\n",
    "                out = torch.cat((a,v),1)\n",
    "                out = self.fusion_module(out)\n",
    "                return a,v,out,self.update\n",
    "\n",
    "            else:\n",
    "                out = torch.cat((a,v),1)\n",
    "                out = self.fusion_module(out)\n",
    "                # self.update = [1] * B\n",
    "                return a,v,out\n",
    "        \n",
    "        else:\n",
    "            if drop != None:\n",
    "                for i in range(len(drop)):\n",
    "                    if drop[i] == 1:\n",
    "                        a[i,:] = 0.0\n",
    "                    elif drop[i] == 2:\n",
    "                        v[i,:] = 0.0\n",
    "\n",
    "            out = torch.cat((a,v),1)\n",
    "            out = self.fusion_module(out)\n",
    "\n",
    "            return a, v, out\n",
    "    \n",
    "    def exec_drop(self, a, v, drop):\n",
    "        if drop == 'audio':\n",
    "            ad = torch.zeros_like(a)\n",
    "            vd = v\n",
    "        \n",
    "        else:\n",
    "            ad = a\n",
    "            vd = torch.zeros_like(v)\n",
    "        \n",
    "        out = torch.cat((ad,vd),1)\n",
    "        out = self.fusion_module(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20128ab",
   "metadata": {
    "papermill": {
     "duration": 0.067499,
     "end_time": "2025-03-19T11:56:59.796117",
     "exception": false,
     "start_time": "2025-03-19T11:56:59.728618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Modify sample_level.py. This is like the main.py for the sample-level solution implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d22398ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:56:59.932494Z",
     "iopub.status.busy": "2025-03-19T11:56:59.932271Z",
     "iopub.status.idle": "2025-03-19T11:56:59.938255Z",
     "shell.execute_reply": "2025-03-19T11:56:59.937550Z"
    },
    "papermill": {
     "duration": 0.075647,
     "end_time": "2025-03-19T11:56:59.939451",
     "exception": false,
     "start_time": "2025-03-19T11:56:59.863804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/sample-level-multimodal-level-multimodal-learning/code/sample_level.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/sample-level-multimodal-level-multimodal-learning/code/sample_level.py\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/working/sample-level-multimodal-level-multimodal-learning/code\")\n",
    "import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datasets.dataloader import CramedDataset,CramedDataset_sample_level\n",
    "from models.models import AVClassifier\n",
    "import random\n",
    "\n",
    "sample_nums = []\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\n",
    "### key parameters:\n",
    "## --warmup: warm up epochs. Default 5 epochs.\n",
    "\n",
    "\n",
    "def get_arguments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', default='CREMAD', type=str,\n",
    "                        help='VGGSound, KineticSound, CREMAD, AVE')\n",
    "    parser.add_argument('--fps', default=1, type=int)\n",
    "    parser.add_argument('--audio_path', default='/kaggle/input/cremad/AudioWAV/AudioWAV', type=str)\n",
    "    parser.add_argument('--visual_path', default='/kaggle/input/cremad/Image-01-FPS', type=str)\n",
    "    parser.add_argument(\"--model\", default=\"resnet18\", type=str, choices=[\"resnet18\"])\n",
    "    parser.add_argument(\n",
    "        \"--modulation\", default=\"sample\", type=str, choices=[\"sample\", \"modality\"]\n",
    "    )\n",
    "    parser.add_argument(\"--compare\", default=\"none\", type=str, choices=[\"none\"])\n",
    "    parser.add_argument(\"--n_classes\", default=6, type=int)\n",
    "    parser.add_argument(\"--batch_size\", default=64, type=int)\n",
    "    parser.add_argument(\"--epochs\", default=60, type=int)\n",
    "    parser.add_argument(\"--loader\", default=165, type=int)\n",
    "    parser.add_argument(\"--warmup\", default=5, type=int)\n",
    "    parser.add_argument(\"--bottom\", default=5, type=int)\n",
    "    parser.add_argument(\"--method\", default='Concat', type=str)\n",
    "    parser.add_argument(\n",
    "        \"--encoder_lr_decay\", default=0.1, type=float, help=\"decay coefficient\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--optimizer\", default=\"adam\", type=str, choices=[\"sgd\", \"adam\"])\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\", default=5e-05, type=float, help=\"initial learning rate\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr_decay_step\", default=30, type=int, help=\"where learning rate decays\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr_decay_ratio\", default=0.1, type=float, help=\"decay coefficient\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--train\", action=\"store_true\", help=\"turn on train mode\")\n",
    "    parser.add_argument(\n",
    "        \"--log_path\",\n",
    "        default=\"log_sample\",\n",
    "        type=str,\n",
    "        help=\"path to save tensorboard logs\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--random_seed\", default=0, type=int)\n",
    "    parser.add_argument(\"--gpu_ids\", default=\"0, 1\", type=str, help=\"GPU ids\")\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def execute_modulation(args, model, device, dataloader, log_name, epoch):\n",
    "    n_classes = args.n_classes\n",
    "\n",
    "    contribution = {}\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    cona = 0.0\n",
    "    conv = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for step, (image, spec, label, index) in tqdm(enumerate(dataloader)):\n",
    "            image = image.to(device)\n",
    "            spec = spec.to(device)\n",
    "            # label = label.to(device)\n",
    "            a, v, out = model(spec.unsqueeze(1).float(), image.float())\n",
    "\n",
    "            out_v = model.module.exec_drop(a, v, drop=\"audio\")\n",
    "            out_a = model.module.exec_drop(a, v, drop=\"visual\")\n",
    "\n",
    "            prediction = softmax(out)\n",
    "            pred_v = softmax(out_v)\n",
    "            pred_a = softmax(out_a)\n",
    "\n",
    "            for i, item in enumerate(label):\n",
    "                all = prediction[i].cpu().data.numpy()\n",
    "                index_all = np.argmax(all)\n",
    "                v = pred_v[i].cpu().data.numpy()\n",
    "                index_v = np.argmax(v)\n",
    "                a = pred_a[i].cpu().data.numpy()\n",
    "                index_a = np.argmax(a)\n",
    "\n",
    "                value_all = 0.0\n",
    "                value_a = 0.0\n",
    "                value_v = 0.0\n",
    "                if index_all == label[i]:\n",
    "                    value_all = 2.0\n",
    "                if index_v == label[i]:\n",
    "                    value_v = 1.0\n",
    "                if index_a == label[i]:\n",
    "                    value_a = 1.0\n",
    "\n",
    "                contrib_a = (value_a + value_all - value_v) / 2.0\n",
    "                contrib_v = (value_v + value_all - value_a) / 2.0\n",
    "                cona += contrib_a\n",
    "                conv += contrib_v\n",
    "\n",
    "                contribution[int(index[i])] = (contrib_a, contrib_v)\n",
    "\n",
    "    cona /= len(dataloader.dataset)\n",
    "    conv /= len(dataloader.dataset)\n",
    "\n",
    "    if not os.path.exists(args.log_path + \"/\" + log_name):\n",
    "        os.mkdir(args.log_path + \"/\" + log_name)\n",
    "    if not os.path.exists(args.log_path + \"/\" + log_name + \"/contribution\"):\n",
    "        os.mkdir(args.log_path + \"/\" + log_name + \"/contribution\")\n",
    "    np.save(\n",
    "        args.log_path + \"/\" + log_name + \"/contribution/\" + str(epoch) + \".npy\",\n",
    "        contribution,\n",
    "    )\n",
    "    print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "    print(\"now train epoch, cona and conv: \", cona, conv)\n",
    "    print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "\n",
    "    train_dataloader = None\n",
    "    # print(contribution.keys())\n",
    "    if epoch >= args.warmup - 1:\n",
    "        train_dataset = CramedDataset_sample_level(\n",
    "            mode=\"train\", args=args, contribution=contribution\n",
    "        )\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=32,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    return cona, conv, train_dataloader\n",
    "\n",
    "\n",
    "def train_epoch(args, epoch, model, device, dataloader, optimizer):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    print(\"Start training ... \")\n",
    "\n",
    "    _loss = 0\n",
    "\n",
    "    for step, (image, spec, label, index, drop) in tqdm(enumerate(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        image = image.to(device)\n",
    "        spec = spec.to(device)\n",
    "        label = label.to(device)\n",
    "        drop = drop.to(device)\n",
    "        a, v, out = model(spec.unsqueeze(1).float(), image.float(), drop)\n",
    "\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        _loss += loss.item()\n",
    "\n",
    "    sample_nums.append(len(dataloader.dataset))\n",
    "\n",
    "    return _loss / len(dataloader)\n",
    "\n",
    "\n",
    "def warmup_epoch(args, epoch, model, device, dataloader, optimizer):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    print(\"Warm up ... \")\n",
    "\n",
    "    _loss = 0\n",
    "\n",
    "    for step, (image, spec, label, index) in tqdm(enumerate(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        image = image.to(device)\n",
    "        spec = spec.to(device)\n",
    "        label = label.to(device)\n",
    "        # print(f\"Image: {image.shape}\") # [64, 3, 1, 224, 224]\n",
    "        # print(f\"Audio: {spec.shape}\") # [64, 257, 300]\n",
    "        a, v, out = model(spec.unsqueeze(1).float(), image.float()) #image:[64,3,1,224,224];  audio:[64,1,257,300]\n",
    "\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        _loss += loss.item()\n",
    "\n",
    "    return _loss / len(dataloader)\n",
    "\n",
    "\n",
    "def valid(args, model, device, dataloader, epoch, log_name):\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    print('testing...')\n",
    "    n_classes = args.n_classes\n",
    "\n",
    "    cri = nn.CrossEntropyLoss()\n",
    "    _loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        num = [0.0 for _ in range(n_classes)]\n",
    "        acc = [0.0 for _ in range(n_classes)]\n",
    "\n",
    "        for step, (image, spec, label, index) in tqdm(enumerate(dataloader)):\n",
    "            image = image.to(device)\n",
    "            spec = spec.to(device)\n",
    "            label = label.to(device)\n",
    "            a, v, out = model(spec.unsqueeze(1).float(), image.float())\n",
    "\n",
    "            prediction = softmax(out)\n",
    "            loss = cri(out, label)\n",
    "            _loss += loss.item()\n",
    "\n",
    "            for i, item in enumerate(label):\n",
    "                ma = prediction[i].cpu().data.numpy()\n",
    "                index_ma = np.argmax(ma)\n",
    "                num[label[i]] += 1.0\n",
    "                if index_ma == label[i]:\n",
    "                    acc[label[i]] += 1.0\n",
    "\n",
    "    return sum(acc) / sum(num)\n",
    "\n",
    "\n",
    "def main():\n",
    "    cona_all = []\n",
    "    conv_all = []\n",
    "    args = get_arguments()\n",
    "    print(args)\n",
    "\n",
    "    setup_seed(args.random_seed)\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_ids\n",
    "    # gpu_ids = list(range(torch.cuda.device_count()))\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    model = AVClassifier(args)\n",
    "\n",
    "    model.to(device)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.cuda()\n",
    "\n",
    "    train_dataset = CramedDataset(mode=\"train\", args=args)\n",
    "    train_val_dataset = CramedDataset(mode=\"train\", args=args)\n",
    "    test_dataset = CramedDataset(mode=\"test\", args=args)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=32,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    train_val_dataloader = DataLoader(\n",
    "        train_val_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=32,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=32\n",
    "    )\n",
    "\n",
    "    if args.optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(), lr=args.learning_rate, momentum=0.9, weight_decay=1e-4\n",
    "        )\n",
    "    elif args.optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=args.learning_rate,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "            weight_decay=1e-4,\n",
    "            amsgrad=False,\n",
    "        )\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, args.lr_decay_step, args.lr_decay_ratio\n",
    "    )\n",
    "\n",
    "    if args.train:\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(args.epochs):\n",
    "            print(\"Epoch: {}: \".format(epoch))\n",
    "            writer_path = os.path.join(args.log_path)\n",
    "            if not os.path.exists(writer_path):\n",
    "                os.mkdir(writer_path)\n",
    "            log_name = \"{}_{}_{}_{}_{}_epochs{}_batch{}_lr{}_en{}_warmup{}\".format(\n",
    "                args.compare,\n",
    "                args.optimizer,\n",
    "                args.dataset,\n",
    "                args.modulation,\n",
    "                args.model,\n",
    "                args.epochs,\n",
    "                args.batch_size,\n",
    "                args.learning_rate,\n",
    "                args.encoder_lr_decay,\n",
    "                args.warmup,\n",
    "            )\n",
    "\n",
    "            if epoch < args.warmup:\n",
    "                batch_loss = warmup_epoch(\n",
    "                    args, epoch, model, device, train_dataloader, optimizer\n",
    "                )\n",
    "            else:\n",
    "                batch_loss = train_epoch(\n",
    "                    args, epoch, model, device, train_dataloader, optimizer\n",
    "                )\n",
    "\n",
    "            if epoch >= args.warmup - 1:\n",
    "                cona, conv, train_dataloader = execute_modulation(\n",
    "                    args, model, device, train_val_dataloader, log_name, epoch\n",
    "                )\n",
    "            else:\n",
    "                cona, conv, _ = execute_modulation(\n",
    "                    args, model, device, train_val_dataloader, log_name, epoch\n",
    "                )\n",
    "            cona_all.append(cona)\n",
    "            conv_all.append(conv)\n",
    "            scheduler.step()\n",
    "            acc = valid(args, model, device, test_dataloader, epoch, log_name)\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = float(acc)\n",
    "\n",
    "                model_name = \"{}_best_model_of_{}_{}_{}_{}_epochs{}_batch{}_lr{}_en{}_warmup{}_bottom{}_{}.pth\".format(\n",
    "                    args.compare,\n",
    "                    args.optimizer,\n",
    "                    args.dataset,\n",
    "                    args.modulation,\n",
    "                    args.model,\n",
    "                    args.epochs,\n",
    "                    args.batch_size,\n",
    "                    args.learning_rate,\n",
    "                    args.encoder_lr_decay,\n",
    "                    args.warmup,\n",
    "                    args.bottom,\n",
    "                    args.method,\n",
    "                )\n",
    "\n",
    "                saved_dict = {\n",
    "                    \"saved_epoch\": epoch,\n",
    "                    \"acc\": acc,\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"scheduler\": scheduler.state_dict(),\n",
    "                }\n",
    "\n",
    "                save_dir = os.path.join(args.log_path, model_name)\n",
    "\n",
    "                torch.save(saved_dict, save_dir)\n",
    "                print(\"The best model has been saved at {}.\".format(save_dir))\n",
    "                print(\"Loss: {:.4f}, Acc: {:.4f}\".format(batch_loss, acc))\n",
    "\n",
    "            else:\n",
    "                print(\n",
    "                    \"Loss: {:.4f}, Acc: {:.4f}, Best Acc: {:.4f}\".format(\n",
    "                        batch_loss, acc, best_acc\n",
    "                    )\n",
    "                )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25e9c689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:57:00.074886Z",
     "iopub.status.busy": "2025-03-19T11:57:00.074683Z",
     "iopub.status.idle": "2025-03-19T11:57:00.197819Z",
     "shell.execute_reply": "2025-03-19T11:57:00.196937Z"
    },
    "papermill": {
     "duration": 0.191963,
     "end_time": "2025-03-19T11:57:00.199062",
     "exception": false,
     "start_time": "2025-03-19T11:57:00.007099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!touch /kaggle/working/sample-level-multimodal-level-multimodal-learning/code/datasets/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8406fa66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:57:00.336667Z",
     "iopub.status.busy": "2025-03-19T11:57:00.336375Z",
     "iopub.status.idle": "2025-03-19T11:57:00.341323Z",
     "shell.execute_reply": "2025-03-19T11:57:00.340564Z"
    },
    "papermill": {
     "duration": 0.075343,
     "end_time": "2025-03-19T11:57:00.342576",
     "exception": false,
     "start_time": "2025-03-19T11:57:00.267233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/sample-level-multimodal-level-multimodal-learning/code\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/sample-level-multimodal-level-multimodal-learning/code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0197164",
   "metadata": {
    "papermill": {
     "duration": 0.070853,
     "end_time": "2025-03-19T11:57:00.481035",
     "exception": false,
     "start_time": "2025-03-19T11:57:00.410182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Run the sample-level code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7cfbea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T11:57:00.617028Z",
     "iopub.status.busy": "2025-03-19T11:57:00.616798Z",
     "iopub.status.idle": "2025-03-19T14:44:12.477937Z",
     "shell.execute_reply": "2025-03-19T14:44:12.476908Z"
    },
    "papermill": {
     "duration": 10031.930662,
     "end_time": "2025-03-19T14:44:12.479472",
     "exception": false,
     "start_time": "2025-03-19T11:57:00.548810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='CREMAD', fps=1, audio_path='/kaggle/input/cremad/AudioWAV/AudioWAV', visual_path='/kaggle/input/cremad/Image-01-FPS', model='resnet18', modulation='sample', compare='none', n_classes=6, batch_size=64, epochs=60, loader=165, warmup=5, bottom=5, method='Concat', encoder_lr_decay=0.1, optimizer='adam', learning_rate=5e-05, lr_decay_step=30, lr_decay_ratio=0.1, train=True, log_path='best_model', random_seed=0, gpu_ids='0, 1')\r\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\r\n",
      "  warnings.warn(\r\n",
      "Epoch: 0: \r\n",
      "Warm up ... \r\n",
      "105it [03:22,  1.93s/it]\r\n",
      "105it [00:59,  1.76it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  0.549492385786802 0.31315318005374737\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "testing...\r\n",
      "12it [00:13,  1.14s/it]\r\n",
      "The best model has been saved at best_model/none_best_model_of_adam_CREMAD_sample_resnet18_epochs60_batch64_lr5e-05_en0.1_warmup5_bottom5_Concat.pth.\r\n",
      "Loss: 1.4719, Acc: 0.3844\r\n",
      "Epoch: 1: \r\n",
      "Warm up ... \r\n",
      "105it [01:19,  1.32it/s]\r\n",
      "105it [01:01,  1.72it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  0.6292176769184832 0.41557181248133773\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "testing...\r\n",
      "12it [00:10,  1.12it/s]\r\n",
      "The best model has been saved at best_model/none_best_model_of_adam_CREMAD_sample_resnet18_epochs60_batch64_lr5e-05_en0.1_warmup5_bottom5_Concat.pth.\r\n",
      "Loss: 1.2285, Acc: 0.4839\r\n",
      "Epoch: 2: \r\n",
      "Warm up ... \r\n",
      "105it [01:15,  1.39it/s]\r\n",
      "105it [00:55,  1.89it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  0.8214392355927143 0.5183636906539265\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "testing...\r\n",
      "12it [00:10,  1.13it/s]\r\n",
      "The best model has been saved at best_model/none_best_model_of_adam_CREMAD_sample_resnet18_epochs60_batch64_lr5e-05_en0.1_warmup5_bottom5_Concat.pth.\r\n",
      "Loss: 0.9586, Acc: 0.5712\r\n",
      "Epoch: 3: \r\n",
      "Warm up ... \r\n",
      "105it [01:16,  1.38it/s]\r\n",
      "105it [01:00,  1.74it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  0.8754105703194983 0.5285906240668856\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "testing...\r\n",
      "12it [00:13,  1.16s/it]\r\n",
      "Loss: 0.6889, Acc: 0.5282, Best Acc: 0.5712\r\n",
      "Epoch: 4: \r\n",
      "Warm up ... \r\n",
      "105it [01:21,  1.30it/s]\r\n",
      "105it [01:01,  1.71it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0743505524037027 0.6527321588533891\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.02it/s]\r\n",
      "The best model has been saved at best_model/none_best_model_of_adam_CREMAD_sample_resnet18_epochs60_batch64_lr5e-05_en0.1_warmup5_bottom5_Concat.pth.\r\n",
      "Loss: 0.4343, Acc: 0.6035\r\n",
      "Epoch: 5: \r\n",
      "Start training ... \r\n",
      "231it [02:06,  1.82it/s]\r\n",
      "105it [00:55,  1.88it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.1175724096745296 0.7991191400418035\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.04s/it]\r\n",
      "Loss: 0.7220, Acc: 0.5712, Best Acc: 0.6035\r\n",
      "Epoch: 6: \r\n",
      "Start training ... \r\n",
      "178it [01:50,  1.61it/s]\r\n",
      "105it [01:01,  1.71it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.203493580173186 0.7466407882950135\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.02it/s]\r\n",
      "Loss: 0.4776, Acc: 0.5766, Best Acc: 0.6035\r\n",
      "Epoch: 7: \r\n",
      "Start training ... \r\n",
      "187it [01:48,  1.72it/s]\r\n",
      "105it [00:55,  1.88it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.1030904747685877 0.8643624962675426\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.05s/it]\r\n",
      "Loss: 0.3962, Acc: 0.5968, Best Acc: 0.6035\r\n",
      "Epoch: 8: \r\n",
      "Start training ... \r\n",
      "161it [01:44,  1.55it/s]\r\n",
      "105it [01:00,  1.73it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.205285159749179 0.7762018512988952\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.08it/s]\r\n",
      "Loss: 0.2720, Acc: 0.6035, Best Acc: 0.6035\r\n",
      "Epoch: 9: \r\n",
      "Start training ... \r\n",
      "155it [01:36,  1.61it/s]\r\n",
      "105it [00:55,  1.88it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.1443714541654224 0.8338309943266646\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.05s/it]\r\n",
      "Loss: 0.2702, Acc: 0.5645, Best Acc: 0.6035\r\n",
      "Epoch: 10: \r\n",
      "Start training ... \r\n",
      "148it [01:39,  1.49it/s]\r\n",
      "105it [01:01,  1.70it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.1463123320394148 0.8256195879366975\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.08it/s]\r\n",
      "Loss: 0.2107, Acc: 0.5632, Best Acc: 0.6035\r\n",
      "Epoch: 11: \r\n",
      "Start training ... \r\n",
      "147it [01:33,  1.58it/s]\r\n",
      "105it [00:55,  1.89it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0599432666467603 0.8812332039414751\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.06it/s]\r\n",
      "Loss: 0.1892, Acc: 0.5954, Best Acc: 0.6035\r\n",
      "Epoch: 12: \r\n",
      "Start training ... \r\n",
      "150it [01:34,  1.59it/s]\r\n",
      "105it [01:00,  1.74it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.1063750373245744 0.8921319796954315\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.05s/it]\r\n",
      "The best model has been saved at best_model/none_best_model_of_adam_CREMAD_sample_resnet18_epochs60_batch64_lr5e-05_en0.1_warmup5_bottom5_Concat.pth.\r\n",
      "Loss: 0.1684, Acc: 0.6559\r\n",
      "Epoch: 13: \r\n",
      "Start training ... \r\n",
      "129it [01:33,  1.39it/s]\r\n",
      "105it [01:00,  1.73it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.1753508510002986 0.7995670349358017\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.05it/s]\r\n",
      "Loss: 0.1346, Acc: 0.5632, Best Acc: 0.6559\r\n",
      "Epoch: 14: \r\n",
      "Start training ... \r\n",
      "156it [01:40,  1.56it/s]\r\n",
      "105it [01:04,  1.63it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0482979994028068 0.8866079426694535\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:13,  1.10s/it]\r\n",
      "Loss: 0.1760, Acc: 0.5497, Best Acc: 0.6559\r\n",
      "Epoch: 15: \r\n",
      "Start training ... \r\n",
      "162it [01:48,  1.49it/s]\r\n",
      "105it [00:59,  1.76it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.1290683786204838 0.8428635413556286\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.01it/s]\r\n",
      "Loss: 0.1606, Acc: 0.5645, Best Acc: 0.6559\r\n",
      "Epoch: 16: \r\n",
      "Start training ... \r\n",
      "155it [01:38,  1.57it/s]\r\n",
      "105it [00:58,  1.79it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.1263810092564945 0.866751269035533\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.08s/it]\r\n",
      "Loss: 0.1442, Acc: 0.5793, Best Acc: 0.6559\r\n",
      "Epoch: 17: \r\n",
      "Start training ... \r\n",
      "140it [01:37,  1.43it/s]\r\n",
      "105it [01:04,  1.63it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0479247536578082 0.9380412063302478\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.05it/s]\r\n",
      "Loss: 0.1239, Acc: 0.5860, Best Acc: 0.6559\r\n",
      "Epoch: 18: \r\n",
      "Start training ... \r\n",
      "136it [01:30,  1.51it/s]\r\n",
      "105it [00:57,  1.82it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.1195879366975217 0.840997312630636\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.04it/s]\r\n",
      "Loss: 0.1199, Acc: 0.5430, Best Acc: 0.6559\r\n",
      "Epoch: 19: \r\n",
      "Start training ... \r\n",
      "147it [01:36,  1.52it/s]\r\n",
      "105it [01:02,  1.69it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0441922962078232 0.9504329650641983\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:13,  1.10s/it]\r\n",
      "Loss: 0.1056, Acc: 0.6116, Best Acc: 0.6559\r\n",
      "Epoch: 20: \r\n",
      "Start training ... \r\n",
      "122it [01:30,  1.36it/s]\r\n",
      "105it [00:57,  1.83it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.07002090176172 0.9263959390862944\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:10,  1.10it/s]\r\n",
      "Loss: 0.0851, Acc: 0.6062, Best Acc: 0.6559\r\n",
      "Epoch: 21: \r\n",
      "Start training ... \r\n",
      "124it [01:25,  1.45it/s]\r\n",
      "105it [01:02,  1.67it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0350851000298598 0.9246043595103016\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.06s/it]\r\n",
      "Loss: 0.1081, Acc: 0.5497, Best Acc: 0.6559\r\n",
      "Epoch: 22: \r\n",
      "Start training ... \r\n",
      "142it [01:38,  1.45it/s]\r\n",
      "105it [01:04,  1.64it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0762167811286951 0.914228127799343\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.04it/s]\r\n",
      "Loss: 0.1783, Acc: 0.6546, Best Acc: 0.6559\r\n",
      "Epoch: 23: \r\n",
      "Start training ... \r\n",
      "131it [01:28,  1.48it/s]\r\n",
      "105it [00:57,  1.83it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0245595700209018 0.96498954911914\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.04it/s]\r\n",
      "Loss: 0.1182, Acc: 0.5968, Best Acc: 0.6559\r\n",
      "Epoch: 24: \r\n",
      "Start training ... \r\n",
      "122it [01:30,  1.35it/s]\r\n",
      "105it [01:02,  1.67it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0506867721707973 0.9469244550612123\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.07s/it]\r\n",
      "The best model has been saved at best_model/none_best_model_of_adam_CREMAD_sample_resnet18_epochs60_batch64_lr5e-05_en0.1_warmup5_bottom5_Concat.pth.\r\n",
      "Loss: 0.0751, Acc: 0.6599\r\n",
      "Epoch: 25: \r\n",
      "Start training ... \r\n",
      "119it [01:29,  1.33it/s]\r\n",
      "105it [00:58,  1.80it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0470289638698118 0.9481934905942072\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.09it/s]\r\n",
      "Loss: 0.0702, Acc: 0.6371, Best Acc: 0.6599\r\n",
      "Epoch: 26: \r\n",
      "Start training ... \r\n",
      "131it [01:28,  1.48it/s]\r\n",
      "105it [00:57,  1.82it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0967452971036131 0.9020603165123917\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.07s/it]\r\n",
      "Loss: 0.0623, Acc: 0.6331, Best Acc: 0.6599\r\n",
      "Epoch: 27: \r\n",
      "Start training ... \r\n",
      "129it [01:33,  1.38it/s]\r\n",
      "105it [01:02,  1.67it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0807703792176768 0.9156464616303374\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.08it/s]\r\n",
      "Loss: 0.0657, Acc: 0.6035, Best Acc: 0.6599\r\n",
      "Epoch: 28: \r\n",
      "Start training ... \r\n",
      "125it [01:25,  1.46it/s]\r\n",
      "105it [00:57,  1.82it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0058226336219767 0.9365482233502538\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:10,  1.10it/s]\r\n",
      "Loss: 0.0610, Acc: 0.5780, Best Acc: 0.6599\r\n",
      "Epoch: 29: \r\n",
      "Start training ... \r\n",
      "143it [01:33,  1.53it/s]\r\n",
      "105it [01:02,  1.67it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0898775753956405 0.9077336518363691\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:13,  1.11s/it]\r\n",
      "Loss: 0.0539, Acc: 0.5968, Best Acc: 0.6599\r\n",
      "Epoch: 30: \r\n",
      "Start training ... \r\n",
      "125it [01:31,  1.37it/s]\r\n",
      "105it [01:02,  1.68it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0056733353239773 0.9937294714840251\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:10,  1.09it/s]\r\n",
      "Loss: 0.0816, Acc: 0.6586, Best Acc: 0.6599\r\n",
      "Epoch: 31: \r\n",
      "Start training ... \r\n",
      "107it [01:19,  1.35it/s]\r\n",
      "105it [00:57,  1.83it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0056733353239773 0.9937294714840251\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:13,  1.13s/it]\r\n",
      "The best model has been saved at best_model/none_best_model_of_adam_CREMAD_sample_resnet18_epochs60_batch64_lr5e-05_en0.1_warmup5_bottom5_Concat.pth.\r\n",
      "Loss: 0.0194, Acc: 0.6828\r\n",
      "Epoch: 32: \r\n",
      "Start training ... \r\n",
      "107it [01:24,  1.26it/s]\r\n",
      "105it [01:03,  1.66it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0046282472379815 0.9947745595700209\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.08it/s]\r\n",
      "Loss: 0.0125, Acc: 0.6828, Best Acc: 0.6828\r\n",
      "Epoch: 33: \r\n",
      "Start training ... \r\n",
      "106it [01:18,  1.35it/s]\r\n",
      "105it [00:57,  1.81it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.002985965959988 0.9964168408480143\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.04it/s]\r\n",
      "Loss: 0.0091, Acc: 0.6761, Best Acc: 0.6828\r\n",
      "Epoch: 34: \r\n",
      "Start training ... \r\n",
      "106it [01:18,  1.35it/s]\r\n",
      "105it [01:03,  1.66it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0023141236189907 0.9973872797850104\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:13,  1.09s/it]\r\n",
      "Loss: 0.0068, Acc: 0.6828, Best Acc: 0.6828\r\n",
      "Epoch: 35: \r\n",
      "Start training ... \r\n",
      "106it [01:23,  1.27it/s]\r\n",
      "105it [01:04,  1.63it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.001716930426993 0.9979844729770081\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.03it/s]\r\n",
      "Loss: 0.0067, Acc: 0.6788, Best Acc: 0.6828\r\n",
      "Epoch: 36: \r\n",
      "Start training ... \r\n",
      "106it [01:18,  1.36it/s]\r\n",
      "105it [00:58,  1.81it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0014929829799941 0.9979098238280084\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:10,  1.10it/s]\r\n",
      "Loss: 0.0058, Acc: 0.6788, Best Acc: 0.6828\r\n",
      "Epoch: 37: \r\n",
      "Start training ... \r\n",
      "106it [01:19,  1.34it/s]\r\n",
      "105it [01:03,  1.66it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0014183338309943 0.9982830695730068\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.07s/it]\r\n",
      "Loss: 0.0067, Acc: 0.6801, Best Acc: 0.6828\r\n",
      "Epoch: 38: \r\n",
      "Start training ... \r\n",
      "106it [01:24,  1.26it/s]\r\n",
      "105it [00:58,  1.80it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0016422812779935 0.9977605255300089\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:10,  1.09it/s]\r\n",
      "Loss: 0.0058, Acc: 0.6680, Best Acc: 0.6828\r\n",
      "Epoch: 39: \r\n",
      "Start training ... \r\n",
      "106it [01:18,  1.35it/s]\r\n",
      "105it [00:57,  1.84it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0018662287249924 0.9978351746790086\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:13,  1.11s/it]\r\n",
      "Loss: 0.0061, Acc: 0.6720, Best Acc: 0.6828\r\n",
      "Epoch: 40: \r\n",
      "Start training ... \r\n",
      "106it [01:24,  1.26it/s]\r\n",
      "105it [01:03,  1.66it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0010450880859958 0.9989549119140042\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.07s/it]\r\n",
      "Loss: 0.0053, Acc: 0.6774, Best Acc: 0.6828\r\n",
      "Epoch: 41: \r\n",
      "Start training ... \r\n",
      "105it [01:23,  1.25it/s]\r\n",
      "105it [00:58,  1.80it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0010450880859958 0.9983577187220065\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.09it/s]\r\n",
      "The best model has been saved at best_model/none_best_model_of_adam_CREMAD_sample_resnet18_epochs60_batch64_lr5e-05_en0.1_warmup5_bottom5_Concat.pth.\r\n",
      "Loss: 0.0034, Acc: 0.6882\r\n",
      "Epoch: 42: \r\n",
      "Start training ... \r\n",
      "106it [01:18,  1.36it/s]\r\n",
      "105it [01:03,  1.66it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0016422812779935 0.9977605255300089\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:13,  1.11s/it]\r\n",
      "Loss: 0.0164, Acc: 0.6801, Best Acc: 0.6882\r\n",
      "Epoch: 43: \r\n",
      "Start training ... \r\n",
      "106it [01:23,  1.27it/s]\r\n",
      "105it [01:03,  1.66it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0011943863839952 0.998507017020006\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.05it/s]\r\n",
      "Loss: 0.0056, Acc: 0.6586, Best Acc: 0.6882\r\n",
      "Epoch: 44: \r\n",
      "Start training ... \r\n",
      "106it [01:17,  1.36it/s]\r\n",
      "105it [00:57,  1.82it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0014183338309943 0.9985816661690057\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:13,  1.10s/it]\r\n",
      "Loss: 0.0195, Acc: 0.6653, Best Acc: 0.6882\r\n",
      "Epoch: 45: \r\n",
      "Start training ... \r\n",
      "106it [01:23,  1.28it/s]\r\n",
      "105it [01:02,  1.68it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0010450880859958 0.9980591221260078\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:13,  1.10s/it]\r\n",
      "Loss: 0.0253, Acc: 0.6707, Best Acc: 0.6882\r\n",
      "Epoch: 46: \r\n",
      "Start training ... \r\n",
      "106it [01:22,  1.28it/s]\r\n",
      "105it [00:58,  1.80it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.001716930426993 0.9976858763810093\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.08it/s]\r\n",
      "Loss: 0.0077, Acc: 0.6707, Best Acc: 0.6882\r\n",
      "Epoch: 47: \r\n",
      "Start training ... \r\n",
      "106it [01:17,  1.36it/s]\r\n",
      "105it [00:57,  1.82it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.000522544042998 0.9991788593610033\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.07s/it]\r\n",
      "Loss: 0.0061, Acc: 0.6788, Best Acc: 0.6882\r\n",
      "Epoch: 48: \r\n",
      "Start training ... \r\n",
      "105it [01:23,  1.26it/s]\r\n",
      "105it [01:02,  1.68it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.001269035532995 0.9984323678710063\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.06s/it]\r\n",
      "Loss: 0.0037, Acc: 0.6761, Best Acc: 0.6882\r\n",
      "Epoch: 49: \r\n",
      "Start training ... \r\n",
      "106it [01:23,  1.27it/s]\r\n",
      "105it [00:58,  1.78it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.000447894893998 0.9992535085100029\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.02s/it]\r\n",
      "Loss: 0.0038, Acc: 0.6747, Best Acc: 0.6882\r\n",
      "Epoch: 50: \r\n",
      "Start training ... \r\n",
      "105it [01:19,  1.33it/s]\r\n",
      "105it [00:57,  1.83it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0002239474469992 0.9994774559570021\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.08s/it]\r\n",
      "Loss: 0.0029, Acc: 0.6788, Best Acc: 0.6882\r\n",
      "Epoch: 51: \r\n",
      "Start training ... \r\n",
      "105it [01:23,  1.26it/s]\r\n",
      "105it [01:02,  1.69it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0002239474469992 0.9994774559570021\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.06s/it]\r\n",
      "Loss: 0.0026, Acc: 0.6801, Best Acc: 0.6882\r\n",
      "Epoch: 52: \r\n",
      "Start training ... \r\n",
      "105it [01:20,  1.30it/s]\r\n",
      "105it [00:57,  1.82it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0000746491489998 0.9996267542550015\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:10,  1.09it/s]\r\n",
      "Loss: 0.0040, Acc: 0.6734, Best Acc: 0.6882\r\n",
      "Epoch: 53: \r\n",
      "Start training ... \r\n",
      "105it [01:17,  1.35it/s]\r\n",
      "105it [01:03,  1.66it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0000746491489998 0.9996267542550015\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:13,  1.12s/it]\r\n",
      "Loss: 0.0030, Acc: 0.6774, Best Acc: 0.6882\r\n",
      "Epoch: 54: \r\n",
      "Start training ... \r\n",
      "105it [01:23,  1.26it/s]\r\n",
      "105it [01:03,  1.64it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0002985965959987 0.9994028068080024\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.02it/s]\r\n",
      "Loss: 0.0022, Acc: 0.6788, Best Acc: 0.6882\r\n",
      "Epoch: 55: \r\n",
      "Start training ... \r\n",
      "105it [01:17,  1.35it/s]\r\n",
      "105it [00:57,  1.81it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0002239474469992 0.9994774559570021\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:11,  1.09it/s]\r\n",
      "Loss: 0.0029, Acc: 0.6774, Best Acc: 0.6882\r\n",
      "Epoch: 56: \r\n",
      "Start training ... \r\n",
      "105it [01:17,  1.35it/s]\r\n",
      "105it [01:02,  1.68it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  0.9999253508510003 0.999776052553001\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.06s/it]\r\n",
      "Loss: 0.0020, Acc: 0.6788, Best Acc: 0.6882\r\n",
      "Epoch: 57: \r\n",
      "Start training ... \r\n",
      "105it [01:23,  1.26it/s]\r\n",
      "105it [01:03,  1.65it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  0.9999253508510003 0.999776052553001\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:10,  1.09it/s]\r\n",
      "Loss: 0.0019, Acc: 0.6828, Best Acc: 0.6882\r\n",
      "Epoch: 58: \r\n",
      "Start training ... \r\n",
      "105it [01:18,  1.34it/s]\r\n",
      "105it [00:57,  1.82it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0 0.9997014034040012\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:10,  1.10it/s]\r\n",
      "Loss: 0.0016, Acc: 0.6734, Best Acc: 0.6882\r\n",
      "Epoch: 59: \r\n",
      "Start training ... \r\n",
      "105it [01:18,  1.35it/s]\r\n",
      "105it [01:02,  1.69it/s]\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "now train epoch, cona and conv:  1.0000746491489998 0.9996267542550015\r\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n",
      "Data reader finish\r\n",
      "testing...\r\n",
      "12it [00:12,  1.07s/it]\r\n",
      "Loss: 0.0022, Acc: 0.6788, Best Acc: 0.6882\r\n"
     ]
    }
   ],
   "source": [
    "!python3 sample_level.py \\\n",
    "    --train \\\n",
    "    --log_path \"best_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cd48728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T14:44:13.845842Z",
     "iopub.status.busy": "2025-03-19T14:44:13.845259Z",
     "iopub.status.idle": "2025-03-19T14:44:13.849182Z",
     "shell.execute_reply": "2025-03-19T14:44:13.848523Z"
    },
    "papermill": {
     "duration": 0.703404,
     "end_time": "2025-03-19T14:44:13.850484",
     "exception": false,
     "start_time": "2025-03-19T14:44:13.147080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !zip -r /kaggle/working/sample-level-multimodal-level-multimodal-learning/code/best_model.zip /kaggle/working/sample-level-multimodal-level-multimodal-learning/code/best_model"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6080159,
     "sourceId": 9898341,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6901078,
     "sourceId": 11073611,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10303.31367,
   "end_time": "2025-03-19T14:44:15.418030",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-19T11:52:32.104360",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
